#' Normalize read count matrix and de-convolute coy ratio signals
#'
#' @param count a cell-by-bin read count matrix. Column names should be formatted (see
#' example data).
#' @param genome reference genome, "hg19" or "hg38".
#' @param mode a string indicating how to obtain baseline counts of each bin.
#'  * "matched normal sample": baseline is obtained from inferred normal cells
#'  using a matched normal sample. Must provide [count_paired].
#'  * "normal cells": baseline is obtained from normal cells. Must provide [normal_cells].
#'  * "all cells": baseline is obtained from all cells. Can be used when no other
#'  information is available and tumor malignancy is low.
#'  * "none": baseline is obtained from inferred normal cells selected using gene numbers.
#' @param thre_bin,thre_cell real number thresholds between 0 and 1. In count matrix,
#' bins with proportion of zeros greater than [thre_bin] and cells with proportion of zeros
#' greater than [thre_cell] will be removed.
#' @param thre_mappability an integer between 0 and 1000000. Bins with less uniquely
#' mapped positions than the threshold will be removed.
#' @param logFT logical
#' @param dlm_dV,dlm_dW parameters of dynamic linear model. Variances of the
#' observation noise and the system noise, respectively.
#' @param count_paired a cell-by-bin read count matrix of paired normal sample.
#' Only used when [mode] is set to "matched normal sample".
#' @param normal_cells a vector giving normal cells. Should be a subset of rownames of [count].
#' Only used when [mode] is set to "normal cells".
#' @param cell_cluster a vector indicating cell cluster identity of each cell,
#' or "none" if there is no predefined cluster.
#' Only used when [mode] is set to "matched normal sample" or "none".
#' @param cluster_method clustering method, "kmeans" or "hc". Only used when
#' [cell_cluster] is set to "none".
#' @param K number of clusters. Only used when [cell_cluster] is set to "none".
#' @param thre_correlation a real number threshold between 0 and 1. When selecting
#' normal cells using matched normal sample, clusters that have higher similarity
#' than the threshold will be kept.
#' Only used when [mode] is set to "matched normal sample".
#' @param thre_ncell an integer threshold. Clusters with less cell number than the
#' value will be neglected in normal cells selection.
#' Only used when [mode] is set to "matched normal sample" or "none".
#' @param use_max_cor_cluster logical, indicating whether to select only cluster
#' with the highest similarity or all clusters with higher similarities than
#' [thre_correlation].
#' @param cutoff a real number. Copy ratios larger than this value will be set to
#' it.
#' @param output_dir output directory
#' @param output_name output file name, should be ".rds"
#'
#' @return a list of the following objects.
#' * "norm_count": a cell-by-bin normalized read count matrix.
#' * "baseline": a vector. Read count baseline of normal cells.
#' * "norm_count": a cell-by-bin copy ratio matrix without segmentation.
#' @export
#'
#' @examples
#'
normalize <- function(count, genome="hg38", mode="normal cells",
                      thre_bin=0.8, thre_cell=0.8, thre_mappability=500000,
                      logFT=F, dlm_dV=0.3, dlm_dW=0.01,
                      count_paired="none",
                      normal_cells="none",
                      cell_cluster="none", cluster_method="kmeans", K=5,
                      thre_correlation=0.95, use_max_cor_cluster=F, thre_ncell=30,
                      cutoff=3,
                      output_dir="./",
                      output_name="norm_result.rds"){
  count <- t(count)
  if(genome=="hg19"){
    data("bin_info_hg19")
    bin <- bin_info_hg19
  }else if(genome=="hg38"){
    data("bin_info_hg38")
    bin <- bin_info_hg38
  }
  if(mode=="matched normal sample"){
    if(identical(count_paired, "none")){
      print("Count matrix of paired normal sample should be provided")
    }
    use_paired <- T
    count_paired <- t(count_paired)
  }else if(mode=="normal cells"){
    if(identical(normal_cells, "none")){
      print("Normal cells in this sample should be provided")
    }
  }

  ## Step 1: filter bins and cells
  print("Step 1: filtering bins and cells...")
  norm_count <- count
  if(use_paired){
    norm_count <- cbind(count_paired, norm_count)
    thre_zero_bin <- thre_bin # bins with more 0 than thre will be discarded
    temp <- rowSums(norm_count<=0)
    f1 <- temp<thre_zero_bin*dim(norm_count)[2] & bin$map>=thre_mappability
    print(paste("number of bin before filter:", length(f1)))
    print(paste("number of bin after filter:", sum(f1)))
    norm_count <- norm_count[f1, ]
    q <- quantile(norm_count, probs=c(1:100)*0.01)
    # print(q)
    thre <- q[99]
    norm_count[norm_count>thre] <- thre

    thre_zero_cell <- thre_cell # cells with more 0/1 than thre will be discarded
    temp <- colSums(norm_count[, (ncol(count_paired)+1):ncol(norm_count)]<=0)
    f2 <- temp<thre_zero_cell*nrow(norm_count)
    print(paste("number of cells before filter:", length(f2)))
    print(paste("number of cells after filter:", sum(f2)))
    norm_count <- cbind(count_paired[f1,], count[f1,f2])
  }else{
    thre_zero_bin <- thre_bin # bins with more 0 than thre will be discarded
    temp <- rowSums(norm_count<=0)
    f1 <- temp<thre_zero_bin*dim(norm_count)[2] & bin$map>=thre_mappability
    print(paste("number of bin before filter:", length(f1)))
    print(paste("number of bin after filter:", sum(f1)))
    norm_count <- norm_count[f1, ]
    q <- quantile(norm_count, probs=c(1:100)*0.01)
    # print(q)
    thre <- q[99]
    norm_count[norm_count>thre] <- thre

    thre_zero_cell <- thre_cell # cells with more 0 than thre will be discarded
    temp <- colSums(norm_count<=0)
    f2 <- temp<thre_zero_cell*nrow(norm_count)
    print(paste("number of cells before filter:", length(f2)))
    print(paste("number of cells after filter:", sum(f2)))
    norm_count <- count[f1,f2]
  }

  ## Step 2: smooth
  print("Step 2: smoothing read count signals...")
  if(logFT){
    norm_count <- log(sqrt(norm_count)+sqrt(norm_count+1))
  }else{
    norm_count <- log(norm_count+1)
  }
  dlm_sm <- function(y){
    model <- dlm::dlmModPoly(order=1, dV=dlm_dV, dW=dlm_dW)
    x <- dlm::dlmSmooth(y, model)$s
    x <- x[2:length(x)]
    return(x)
  }
  dlm_sm_by_chr <- function(y){
    bin_ <- bin[f1,]
    model <- dlm::dlmModPoly(order=1, dV=dlm_dV, dW=dlm_dW)
    x <- 1:length(y)
    for(i in unique(bin_$chr)){
      f_ <- bin_$chr==i
      if(sum(f_)>2){
        x_ <- dlm::dlmSmooth(y[f_],model)$s
        x[f_] <- x_[-1]
      }else{
        x[f_] <- y[f_]
      }
    }
    return(x)
  }
  temp <- apply(norm_count, 2, dlm_sm)


  norm_count <- exp(temp)
  norm_count <- edgeR::cpm(norm_count)
  norm_count <- log(norm_count+1)

  q <- quantile(norm_count, probs=c(1:100)*0.01)
  thre <- q[99]
  norm_count[norm_count>thre] <- thre

  if(use_paired){
    norm_count_paired <- norm_count[, 1:ncol(count_paired)]
    norm_count <- norm_count[, (ncol(count_paired)+1):ncol(norm_count)]
  }else{
    norm_count <- norm_count
  }

  ## Step 3: decide normal cells
  print("Step 3: calculating baseline of normal cells...")
  baseline <- data.frame(n=c(1:nrow(norm_count)))
  baseline$med_all <- apply(norm_count, 1, median)

  # 3.1 median of all cells
  if(mode=="all cells"){
    baseline$med_paired <- baseline$med_all
    baseline$selected_normal <- baseline$med_all
    print("Baseline is calculated using median read count of all cells")
  }else{
    if(identical(cell_cluster,"none")){
      print("Assigning cell clusters...")
      if(cluster_method=="hc"){
        d <- parallelDist::parallelDist(t(norm_count))
        hc_re <- hclust(d, method="ward.D")
        cluster <- cutree(hc_re, k=K)
      }
      if(cluster_method=="kmeans"){
        temp <- irlba::prcomp_irlba(t(norm_count), n=50)$x
        cluster <- kmeans(temp, centers=K)$cluster
      }
    }else{
      cluster <- as.factor(cell_cluster)
      K <- length(unique(cluster))
    }
  }

  # 3.2 no additinal information
  if(mode=="none"){
    print("Selecting normal cells using correlating with pseudo baseline...")
    baseline$med_paired <- bin$gene[f1]
    corr <- c(1:K)
    for(i in 1:K){
      j <- unique(cluster)[i]
      if(sum(cluster==j)==1){
        baseline[,i+3] <- norm_count[,cluster==j]
      }else{
        baseline[,i+3] <- apply(norm_count[,cluster==j], 1, median)
      }
      corr_ <- cor(baseline[,i+3], baseline$med_paired, method="pearson")
      corr[i] <- corr_
      if(sum(cluster==j)<thre_ncell){
        corr[i] <- -10
      }
      print(paste0("cluster ",j,";",sum(cluster==j),"cells;","corr=",corr_))
    }
    i <- which.max(corr)
    j <- unique(cluster)[i]
    baseline$selected_normal <-
      apply(norm_count[,cluster==j], 1, median)
    print(paste0("selected normal: ", sum(cluster==j), " cells"))
    print(paste0("max correlation to psuedo baseline: ", corr[i]))
    print("Baseline is calculated using median read count of selected normal cells")
  }

  # 3.3 known normal cells
  if(mode=="normal cells"){
    baseline$med_paired <- apply(norm_count_paired, 1, median)
    baseline$selected_normal <- baseline$med_paired
    print("Baseline is calculated using median read count of normal cells")
  }

  # 3.4 paired normal sample
  if(mode=="matched normal sample"){
    print("Selecting normal cells using paired normal sample")
    baseline$med_paired <- apply(norm_count_paired, 1, median)
    corr <- c(1:K)
    for(i in 1:K){
      j <- unique(cluster)[i]
      if(sum(cluster==j)==1){
        baseline[,i+3] <- norm_count[,cluster==j]
      }else{
        baseline[,i+3] <- apply(norm_count[,cluster==j], 1, median)
      }
      corr_ <- cor(baseline[,i+3], baseline$med_paired, method="pearson")
      corr[i] <- corr_
      if(sum(cluster==j)<thre_ncell){
        corr[i] <- -10
      }
      # print(paste0("cluster ",i,";",sum(cluster==i),"cells;","corr=",corr_))
      print(paste0("cluster ",j,";",sum(cluster==j),"cells;","corr=",corr_,
                   ";diff=", mean(abs(baseline$med_paired-baseline[,i+3]))))
    }

    i <- which.max(corr)
    j <- unique(cluster)[i]
    if(use_max_cor_cluster){
      baseline$selected_normal <-
        apply(norm_count[,cluster==j], 1, median)
    }else{
      baseline$selected_normal <-
        apply(norm_count[,cluster %in% unique(cluster)[which(corr>thre_correlation)]], 1, median)
    }

    print(paste0("selected normal: ", sum(cluster==j), " cells"))
    print(paste0("max correlation to paired normal: ", corr[i]))
    if(corr[i]<thre_correlation & use_paired){
      baseline$selected_normal <- baseline$med_paired
      print("Baseline is calculated using median read count of paired sample")
    }else{
      print("Baseline is calculated using median read count of selected normal cells")
    }
  }

  ## Step 4: normalize using baseline
  print("Step 4: normalizing...")
  norm_count_final <- norm_count-baseline$selected_normal
  norm_count_final <- t(norm_count_final)
  norm_count_final <- exp(norm_count_final)
  rownames(norm_count_final) <- colnames(norm_count)[f2]
  q <- quantile(norm_count_final, probs=c(1:100)*0.01)
  print(paste0("99th percentile: ",q[99]))
  if(is.numeric(cutoff) & cutoff>1.5){
    thre1 <- cutoff
  }else{
    thre1 <- q[99]
  }
  norm_count_final[norm_count_final>thre1] <- thre1
  colnames(norm_count_final) <- paste0(bin$chr,"_",bin$start,"_",bin$end)[f1]

  ## Step 5: save results
  if(!dir.exists(output_dir)){
    dir.create(output_dir)
  }
  norm_count <- t(exp(norm_count))
  print("Step 4: saving results...")
  colnames(norm_count) <- colnames(norm_count_final)
  result <- list(copy_ratio=norm_count_final,
                 norm_count=norm_count,
                 baseline=exp(baseline$selected_normal))
  saveRDS(result, paste0(output_dir, output_name))
  return(result)
}
